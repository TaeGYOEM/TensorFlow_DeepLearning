{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.052625 [0.57053506] [1.2773722]\n",
      "1 0.29805407 [0.46042013] [1.1936837]\n",
      "2 0.2072134 [0.48655456] [1.170779]\n",
      "3 0.19645464 [0.49745873] [1.1420014]\n",
      "4 0.18711193 [0.5096967] [1.1146176]\n",
      "5 0.17822383 [0.5214661] [1.0878154]\n",
      "6 0.1697581 [0.53297156] [1.0616659]\n",
      "7 0.1616944 [0.5441984] [1.0361441]\n",
      "8 0.15401383 [0.5551556] [1.011236]\n",
      "9 0.14669804 [0.5658493] [0.9869265]\n",
      "10 0.13972981 [0.576286] [0.96320146]\n",
      "11 0.13309252 [0.5864718] [0.9400468]\n",
      "12 0.12677056 [0.5964127] [0.9174487]\n",
      "13 0.12074882 [0.6061147] [0.89539385]\n",
      "14 0.115013145 [0.6155834] [0.87386924]\n",
      "15 0.10954997 [0.6248245] [0.85286206]\n",
      "16 0.1043463 [0.6338434] [0.83235985]\n",
      "17 0.099389754 [0.64264566] [0.8123505]\n",
      "18 0.09466866 [0.6512362] [0.7928221]\n",
      "19 0.09017185 [0.6596202] [0.77376324]\n",
      "20 0.08588863 [0.66780275] [0.7551625]\n",
      "21 0.08180886 [0.6757885] [0.73700887]\n",
      "22 0.07792286 [0.68358237] [0.7192917]\n",
      "23 0.074221425 [0.6911888] [0.7020004]\n",
      "24 0.07069588 [0.69861245] [0.68512475]\n",
      "25 0.06733779 [0.7058576] [0.6686548]\n",
      "26 0.064139165 [0.71292853] [0.6525808]\n",
      "27 0.06109251 [0.7198296] [0.6368932]\n",
      "28 0.058190554 [0.72656465] [0.62158275]\n",
      "29 0.055426482 [0.73313785] [0.60664034]\n",
      "30 0.052793685 [0.73955303] [0.5920571]\n",
      "31 0.050285965 [0.745814] [0.5778245]\n",
      "32 0.04789731 [0.75192446] [0.56393397]\n",
      "33 0.04562215 [0.757888] [0.55037737]\n",
      "34 0.04345511 [0.76370823] [0.5371467]\n",
      "35 0.041390937 [0.7693885] [0.52423406]\n",
      "36 0.03942482 [0.77493227] [0.51163185]\n",
      "37 0.037552122 [0.78034276] [0.49933258]\n",
      "38 0.03576838 [0.78562313] [0.48732895]\n",
      "39 0.034069337 [0.7907766] [0.4756139]\n",
      "40 0.032451056 [0.7958062] [0.46418047]\n",
      "41 0.03090956 [0.8007149] [0.45302188]\n",
      "42 0.029441359 [0.80550563] [0.44213155]\n",
      "43 0.028042873 [0.81018114] [0.431503]\n",
      "44 0.026710814 [0.8147442] [0.42112994]\n",
      "45 0.025442034 [0.81919765] [0.4110063]\n",
      "46 0.02423352 [0.823544] [0.401126]\n",
      "47 0.02308241 [0.8277859] [0.3914832]\n",
      "48 0.021985976 [0.8319258] [0.3820722]\n",
      "49 0.02094163 [0.83596617] [0.37288746]\n",
      "50 0.019946879 [0.83990943] [0.3639235]\n",
      "51 0.018999385 [0.8437579] [0.35517502]\n",
      "52 0.018096885 [0.84751385] [0.34663686]\n",
      "53 0.017237294 [0.85117954] [0.33830395]\n",
      "54 0.016418504 [0.8547571] [0.33017135]\n",
      "55 0.01563861 [0.8582486] [0.32223424]\n",
      "56 0.014895779 [0.86165625] [0.31448796]\n",
      "57 0.014188208 [0.8649819] [0.30692786]\n",
      "58 0.013514258 [0.8682276] [0.29954952]\n",
      "59 0.012872301 [0.87139535] [0.29234856]\n",
      "60 0.012260876 [0.8744869] [0.2853207]\n",
      "61 0.011678475 [0.87750417] [0.27846178]\n",
      "62 0.0111237345 [0.8804489] [0.27176777]\n",
      "63 0.010595344 [0.8833228] [0.26523465]\n",
      "64 0.010092056 [0.88612765] [0.2588586]\n",
      "65 0.009612683 [0.88886505] [0.2526358]\n",
      "66 0.0091560725 [0.8915367] [0.24656263]\n",
      "67 0.008721147 [0.89414406] [0.24063541]\n",
      "68 0.00830689 [0.89668876] [0.2348507]\n",
      "69 0.007912309 [0.8991723] [0.22920506]\n",
      "70 0.007536461 [0.9015961] [0.22369511]\n",
      "71 0.0071784793 [0.9039617] [0.21831764]\n",
      "72 0.006837491 [0.9062704] [0.21306941]\n",
      "73 0.006512715 [0.9085236] [0.20794737]\n",
      "74 0.006203346 [0.9107226] [0.20294844]\n",
      "75 0.005908694 [0.91286886] [0.19806972]\n",
      "76 0.005628018 [0.91496336] [0.19330823]\n",
      "77 0.005360672 [0.91700757] [0.18866123]\n",
      "78 0.0051060384 [0.9190026] [0.18412594]\n",
      "79 0.0048635085 [0.92094976] [0.17969972]\n",
      "80 0.0046324884 [0.9228501] [0.17537987]\n",
      "81 0.0044124355 [0.92470473] [0.17116387]\n",
      "82 0.0042028516 [0.9265148] [0.16704921]\n",
      "83 0.004003214 [0.9282813] [0.16303346]\n",
      "84 0.0038130544 [0.9300054] [0.15911424]\n",
      "85 0.0036319278 [0.93168795] [0.15528923]\n",
      "86 0.0034594124 [0.9333302] [0.15155621]\n",
      "87 0.0032950845 [0.9349328] [0.14791287]\n",
      "88 0.0031385608 [0.936497] [0.14435714]\n",
      "89 0.0029894852 [0.93802357] [0.14088692]\n",
      "90 0.0028474785 [0.93951344] [0.13750009]\n",
      "91 0.0027122218 [0.94096756] [0.1341947]\n",
      "92 0.0025833936 [0.9423866] [0.13096875]\n",
      "93 0.0024606797 [0.9437716] [0.12782034]\n",
      "94 0.002343797 [0.9451233] [0.12474764]\n",
      "95 0.0022324566 [0.9464424] [0.12174877]\n",
      "96 0.0021264185 [0.94773] [0.11882205]\n",
      "97 0.0020254112 [0.94898653] [0.11596564]\n",
      "98 0.0019292025 [0.95021284] [0.11317791]\n",
      "99 0.0018375659 [0.9514097] [0.11045719]\n",
      "\n",
      "=== Test====\n",
      "X: 5, Y: [4.867506]\n",
      "X: 2.5, Y: [2.4889815]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# -- 그래프 생성 --\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "\n",
    "# -0.1 과 0.1 사이의 균등분포를 가진 무작위 값을 가진 '변수(Varialbe)' 선언\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) \n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) \n",
    "\n",
    "\n",
    "# 플래이스홀더(placholder) 선언 및 이름부여\n",
    "X = tf.placeholder(tf.float32, name=\"X\") \n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "\n",
    "# 선형관계 분석을 위한 수식(X값과 W(가중치),b(편향)를 이용해 Y의 값을 찾는것)\n",
    "hypothesis = W*X+b \n",
    "\n",
    "\n",
    "# 손실 함수 구현 : 실제값과 모델로 예측한 값이 얼마나 차이가 있는지 알 수 있는 함수, 작을 수록 좋음\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# 경사하강법(GradientDescent) 최적화 함수를 이용해 손실값을 최소화 하는 연산그래프 생성\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# -- 그래프 실행 --\n",
    "# 학습을 100번 수행하며 최적화를 수행하는 그래프 train_op를 싱핼하고 실행시 마다 변화하는 손실값 출력\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        print(step,cost_val, sess.run(W), sess.run(b))\n",
    "        \n",
    "    print(\"\\n=== Test====\")\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
