{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.6668686 [0.6549463]\n",
      "1 0.4741315 [0.8159714]\n",
      "2 0.13486403 [0.9018514]\n",
      "3 0.038361333 [0.94765407]\n",
      "4 0.010911698 [0.97208214]\n",
      "5 0.0031037822 [0.98511046]\n",
      "6 0.00088285055 [0.99205893]\n",
      "7 0.0002511163 [0.9957648]\n",
      "8 7.1429065e-05 [0.9977412]\n",
      "9 2.031677e-05 [0.99879533]\n",
      "10 5.77867e-06 [0.9993575]\n",
      "11 1.644013e-06 [0.99965733]\n",
      "12 4.6768554e-07 [0.99981725]\n",
      "13 1.3292599e-07 [0.99990255]\n",
      "14 3.7819973e-08 [0.999948]\n",
      "15 1.0764513e-08 [0.9999723]\n",
      "16 3.0590854e-09 [0.9999852]\n",
      "17 8.6663476e-10 [0.99999213]\n",
      "18 2.407461e-10 [0.9999958]\n",
      "19 7.021583e-11 [0.99999774]\n",
      "20 1.9895197e-11 [0.9999988]\n",
      "=========================Test=======================\n",
      "X: 4, Y:  [3.9999952]\n",
      "X: 7.5, Y:  [7.499991]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "#그래프 구현\n",
    "############\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Linear regression의 구조는 1차 방정식이다. \"x 이걸 넣으면 y에는 이게 나와야 한다\"는 걸 컴퓨터에게 먼저 알려줌.\n",
    "#H(x) = Wx + b training data 입력! \n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    " \n",
    "#placeholder 사용!\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "#Variable 을 사용할때 값을 정할 수 없으니 random을 넣어줌.\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "\n",
    "# Hypothesis = Wx+b => Regression방법에서 학습을 통한 직선을 나타냄\n",
    "hypothesis = X * W\n",
    "\n",
    "#cost(W,b) costFunction\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "#최적화 Gradient descent 방법\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "\n",
    "#가중치 W의 값을 업데이트 시켜주는 것\n",
    "update = W.assign(descent)\n",
    "\n",
    "############\n",
    "#그래프 실행\n",
    "############\n",
    "\n",
    "#그래프를 실행하기위한 session함수 선언\n",
    "sess = tf.Session()\n",
    "\n",
    "# sess을 실행하기위해서는 그래프 구현에서 만든 텐서들을 초기화 시켜줘야하는 과정이 필요함\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#텐서'train'이 모든 텐서의 루트 노드이므로 run시키게 되면 관련된 모든 텐서(노드)들이 전부 실행되게 된다.\n",
    "\n",
    "######################\n",
    "#학습시작(2001번학습!)\n",
    "######################\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_train, Y: y_train})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_train, Y: y_train}), sess.run(W))\n",
    "        \n",
    "        \n",
    "#####################\n",
    "#학습된 그래프 테스트\n",
    "#####################\n",
    "print(\"=========================Test=======================\")\n",
    "print(\"X: 4, Y: \", sess.run(hypothesis, feed_dict={X: 4}))\n",
    "print(\"X: 7.5, Y: \", sess.run(hypothesis, feed_dict={X: 7.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
